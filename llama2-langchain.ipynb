{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 30px; font-weight: bold; background-color: yellow;\">\n",
    "Langchain\n",
    "\n",
    "    LangChain is a framework for developing applications powered by language models.\n",
    "\n",
    "    GitHub: https://github.com/hwchase17/langchain\n",
    "    Docs: https://python.langchain.com/en/latest/index.html\n",
    "        \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 30px; font-weight: bold; background-color: yellow;\">\n",
    "1. Install all the required packages\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://github.com/facebookresearch/llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:42:25.678308Z",
     "iopub.status.busy": "2025-03-14T09:42:25.678001Z",
     "iopub.status.idle": "2025-03-14T09:42:25.898530Z",
     "shell.execute_reply": "2025-03-14T09:42:25.897728Z",
     "shell.execute_reply.started": "2025-03-14T09:42:25.678286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 14 09:42:25 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   38C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:43:37.979689Z",
     "iopub.status.busy": "2025-03-14T09:43:37.979370Z",
     "iopub.status.idle": "2025-03-14T09:43:41.340326Z",
     "shell.execute_reply": "2025-03-14T09:43:41.339317Z",
     "shell.execute_reply.started": "2025-03-14T09:43:37.979664Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers einops accelerate langchain bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 30px; font-weight: bold; background-color: yellow;\">\n",
    "2. Logged in with a Hugging Face account\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a lot of cases, you must be logged in with a Hugging Face account to interact with the Hub: download private repos, upload files, create PRs,…\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/quick-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:48:21.806191Z",
     "iopub.status.busy": "2025-03-14T09:48:21.805849Z",
     "iopub.status.idle": "2025-03-14T09:48:22.337010Z",
     "shell.execute_reply": "2025-03-14T09:48:22.336165Z",
     "shell.execute_reply.started": "2025-03-14T09:48:21.806165Z"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Paste your access token here\n",
    "login(token=\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 30px; font-weight: bold; background-color: yellow;\">\n",
    "3. Import all the required Libraries\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:50:50.692908Z",
     "iopub.status.busy": "2025-03-14T09:50:50.692547Z",
     "iopub.status.idle": "2025-03-14T09:50:59.714322Z",
     "shell.execute_reply": "2025-03-14T09:50:59.713065Z",
     "shell.execute_reply.started": "2025-03-14T09:50:50.692879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.41 (from langchain_community)\n",
      "  Downloading langchain_core-0.3.45-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.20 (from langchain_community)\n",
      "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.3)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain<1.0.0,>=0.3.20->langchain_community)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (2.11.0a2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.26.2->langchain_community) (2.4.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain_community) (2.29.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3,>=1.26.2->langchain_community) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3,>=1.26.2->langchain_community) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain_community) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3,>=1.26.2->langchain_community) (2024.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.2.2)\n",
      "Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.45-py3-none-any.whl (415 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.9/415.9 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, httpx-sse, pydantic-settings, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.25\n",
      "    Uninstalling langchain-core-0.3.25:\n",
      "      Successfully uninstalled langchain-core-0.3.25\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.3\n",
      "    Uninstalling langchain-text-splitters-0.3.3:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.3\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.12\n",
      "    Uninstalling langchain-0.3.12:\n",
      "      Successfully uninstalled langchain-0.3.12\n",
      "Successfully installed httpx-sse-0.4.0 langchain-0.3.20 langchain-core-0.3.45 langchain-text-splitters-0.3.6 langchain_community-0.3.19 pydantic-settings-2.8.1 python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:51:03.353348Z",
     "iopub.status.busy": "2025-03-14T09:51:03.353030Z",
     "iopub.status.idle": "2025-03-14T09:51:03.381489Z",
     "shell.execute_reply": "2025-03-14T09:51:03.380672Z",
     "shell.execute_reply.started": "2025-03-14T09:51:03.353320Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:51:20.325863Z",
     "iopub.status.busy": "2025-03-14T09:51:20.325501Z",
     "iopub.status.idle": "2025-03-14T09:51:28.189662Z",
     "shell.execute_reply": "2025-03-14T09:51:28.188947Z",
     "shell.execute_reply.started": "2025-03-14T09:51:20.325834Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:51:28.191026Z",
     "iopub.status.busy": "2025-03-14T09:51:28.190574Z",
     "iopub.status.idle": "2025-03-14T09:51:28.194534Z",
     "shell.execute_reply": "2025-03-14T09:51:28.193826Z",
     "shell.execute_reply.started": "2025-03-14T09:51:28.190992Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:51:32.591170Z",
     "iopub.status.busy": "2025-03-14T09:51:32.590871Z",
     "iopub.status.idle": "2025-03-14T09:51:32.595241Z",
     "shell.execute_reply": "2025-03-14T09:51:32.594467Z",
     "shell.execute_reply.started": "2025-03-14T09:51:32.591149Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:52:01.893871Z",
     "iopub.status.busy": "2025-03-14T09:52:01.893533Z",
     "iopub.status.idle": "2025-03-14T09:52:01.897312Z",
     "shell.execute_reply": "2025-03-14T09:52:01.896563Z",
     "shell.execute_reply.started": "2025-03-14T09:52:01.893841Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\n",
    "    'ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 30px; font-weight: bold; background-color: yellow;\">\n",
    "4. Load the Llama2 Model\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are using Llama 2 Chat Model with 7 Billion Parameters\n",
    "\n",
    "The basic building block of LangChain is a Large Language Model which takes text as input and generates more text\n",
    "\n",
    "Suppose we want to generate a company name based on the company description. In this case, since we want the output to be more random, we will intialize our model with high temprature.\n",
    "\n",
    "The temperature parameter adjusts the randomness of the output. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n",
    "\n",
    "temperature value--> how creative we want our model to be\n",
    "\n",
    "0 ---> temperature it means model is very safe it is not taking any bets.\n",
    "\n",
    "1 --> it will take risk it might generate wrong output but it is very creative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:54:23.096456Z",
     "iopub.status.busy": "2025-03-14T09:54:23.096138Z",
     "iopub.status.idle": "2025-03-14T09:54:23.100306Z",
     "shell.execute_reply": "2025-03-14T09:54:23.099231Z",
     "shell.execute_reply.started": "2025-03-14T09:54:23.096434Z"
    }
   },
   "outputs": [],
   "source": [
    "model=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# model=\"daryl149/llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:56:00.297744Z",
     "iopub.status.busy": "2025-03-14T09:56:00.297394Z",
     "iopub.status.idle": "2025-03-14T09:56:01.230720Z",
     "shell.execute_reply": "2025-03-14T09:56:01.229751Z",
     "shell.execute_reply.started": "2025-03-14T09:56:00.297718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97104b0e3b92460cb1356309024ae31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe94137a2074a5bba9bb988bbc2036e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ff4d3583d94e66847bfd90ac0b364c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d754458a251d469da1814d4cd0dc1783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:56:15.766366Z",
     "iopub.status.busy": "2025-03-14T09:56:15.766046Z",
     "iopub.status.idle": "2025-03-14T09:57:57.114984Z",
     "shell.execute_reply": "2025-03-14T09:57:57.114289Z",
     "shell.execute_reply.started": "2025-03-14T09:56:15.766340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de22d776e430437d9b695b9bb08daa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5809c18afef74911ac10da1272073e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a393c27b1094828a78bfa3b69f2bcfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52264902af34eac9ebd0fdb78a47a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0059358b913d4de3956ac9a902af720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948248e1e8444c6392b63169875ca7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8722868a50400f8277be9edd8d9287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipeline=transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    max_length=1000,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:57:57.116440Z",
     "iopub.status.busy": "2025-03-14T09:57:57.115877Z",
     "iopub.status.idle": "2025-03-14T09:57:57.356705Z",
     "shell.execute_reply": "2025-03-14T09:57:57.355850Z",
     "shell.execute_reply.started": "2025-03-14T09:57:57.116416Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:57:57.358478Z",
     "iopub.status.busy": "2025-03-14T09:57:57.358177Z",
     "iopub.status.idle": "2025-03-14T09:57:57.362078Z",
     "shell.execute_reply": "2025-03-14T09:57:57.361224Z",
     "shell.execute_reply.started": "2025-03-14T09:57:57.358450Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"What would be a good name for a company that makes colorful socks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:57:57.363388Z",
     "iopub.status.busy": "2025-03-14T09:57:57.363110Z",
     "iopub.status.idle": "2025-03-14T09:58:17.922084Z",
     "shell.execute_reply": "2025-03-14T09:58:17.921262Z",
     "shell.execute_reply.started": "2025-03-14T09:57:57.363360Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would be a good name for a company that makes colorful socks?\n",
      "\n",
      "I'm looking for a name that is fun, playful, and eye-catching. Something that will make people want to buy your socks! Here are a few ideas to get you started:\n",
      "\n",
      "1. SoleMates: This name is a play on the word \"soulmate,\" but with a sock twist. It suggests that the socks are your perfect match.\n",
      "2. HueHues: This name is a play on the word \"hues,\" which means colors. It's a fun and catchy name that will make people take notice.\n",
      "3. Footloose & Fancy-Free: This name is a play on the phrase \"footloose and fancy-free,\" which means feeling carefree and unencumbered. It's a fun and upbeat name that will make people smile.\n",
      "4. Socktastic: This name is a play on the word \"fantastic,\" but with a sock twist. It's a fun and eye-catching name that will make people want to buy your socks.\n",
      "5. The Sock Exchange: This name suggests that the company is a place where you can exchange your old socks for new, colorful ones. It's a fun and creative name that will make people take notice.\n",
      "\n",
      "I hope these ideas help inspire you to come up with the perfect name for your company!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:58:17.923335Z",
     "iopub.status.busy": "2025-03-14T09:58:17.923040Z",
     "iopub.status.idle": "2025-03-14T09:58:17.927516Z",
     "shell.execute_reply": "2025-03-14T09:58:17.926480Z",
     "shell.execute_reply.started": "2025-03-14T09:58:17.923312Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt=\"I want to open a restaurant for  indian food. Suggest me a fence name for this\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:58:17.928887Z",
     "iopub.status.busy": "2025-03-14T09:58:17.928584Z",
     "iopub.status.idle": "2025-03-14T09:59:03.241236Z",
     "shell.execute_reply": "2025-03-14T09:59:03.240426Z",
     "shell.execute_reply.started": "2025-03-14T09:58:17.928856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to open a restaurant for  indian food. Suggest me a fence name for this restaurant.\n",
      "Please provide me a list of 10-15 names for the restaurant.\n",
      "I would like the name to be catchy, unique, and memorable.\n",
      "I want to attract customers from all over the world.\n",
      "\n",
      "I would appreciate any suggestions or ideas you can provide.\n",
      "Thank you.\n",
      "\n",
      "Answer:\n",
      "\n",
      "Certainly! Here are some suggestions for a catchy and memorable name for your Indian restaurant:\n",
      "\n",
      "1. Tandoor Nights - This name plays on the traditional Indian clay oven, known as a tandoor, which is used for cooking naan bread and other dishes.\n",
      "2. Spice Route - This name evokes the historic spice trade routes that brought Indian cuisine to the world.\n",
      "3. Mumbai Bazaar - This name captures the vibrant energy of India's financial capital and suggests a bustling, lively atmosphere.\n",
      "4. Rajmahal Palace - This name combines the words \"raj\" (king) and \"mahal\" (palace), suggesting a regal and luxurious dining experience.\n",
      "5. Tikka Tandoor - This name plays on the popular Indian dish, tikka masala, and the tandoor oven.\n",
      "6. Samosas & Co. - This name is catchy and memorable, and suggests a wide variety of Indian street foods.\n",
      "7. Biryani Bazaar - This name combines the words \"biryani\" (a popular Indian rice dish) and \"bazaar\" (market), suggesting a diverse and extensive menu.\n",
      "8. Curry Leaf Cafe - This name is simple and straightforward, and suggests a cozy and welcoming atmosphere.\n",
      "9. Mint & Basil - This name combines the words \"mint\" (a popular Indian herb) and \"basil\" (a classic Indian flavor), and suggests a fresh and vibrant menu.\n",
      "10. Spice Station - This name suggests a restaurant that offers a wide variety of spices and seasonings, and a menu that is full of flavorful dishes.\n",
      "11. Naan Stop - This name plays on the popular Indian flatbread, naan, and suggests a quick and easy dining experience.\n",
      "12. Kebab Korner - This name combines the words \"kebab\" (a popular Indian meat dish) and \"corner,\" suggesting a cozy and intimate atmosphere.\n",
      "13. Chai Time - This name plays on the popular Indian tea, chai, and suggests a relaxed and comfortable dining experience.\n",
      "14. Tandoor Tales - This name combines the words \"tandoor\" (clay oven) and \"tales,\" suggesting a restaurant with a rich and varied menu.\n",
      "15. Bhel Puri Bar - This name combines the words \"bhel\" (a popular Indian street food) and \"puri\" (a type of Indian bread), and suggests a fun and lively atmosphere.\n",
      "\n",
      "I hope these suggestions help inspire you as you choose a name for your Indian restaurant!\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 30px; font-weight: bold; background-color: yellow;\">\n",
    "5. Prompt Templates \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently in the above applications we are writing an entire prompt, if you are creating a user directed application then this is not an ideal case\n",
    "\n",
    "LangChain faciliates prompt management and optimization.\n",
    "\n",
    "Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you need to take the user input and construct a prompt, and only then send that to the LLM.\n",
    "\n",
    "In many Large Language Model applications we donot pass the user input directly to the Large Language Model, we add the user input to a large piece of text called prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:59:07.259864Z",
     "iopub.status.busy": "2025-03-14T09:59:07.259549Z",
     "iopub.status.idle": "2025-03-14T09:59:07.392375Z",
     "shell.execute_reply": "2025-03-14T09:59:07.391493Z",
     "shell.execute_reply.started": "2025-03-14T09:59:07.259841Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:59:27.864788Z",
     "iopub.status.busy": "2025-03-14T09:59:27.864458Z",
     "iopub.status.idle": "2025-03-14T09:59:27.923851Z",
     "shell.execute_reply": "2025-03-14T09:59:27.922687Z",
     "shell.execute_reply.started": "2025-03-14T09:59:27.864743Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:59:38.738405Z",
     "iopub.status.busy": "2025-03-14T09:59:38.738112Z",
     "iopub.status.idle": "2025-03-14T09:59:38.742172Z",
     "shell.execute_reply": "2025-03-14T09:59:38.741419Z",
     "shell.execute_reply.started": "2025-03-14T09:59:38.738382Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template1=PromptTemplate(input_variables=[\"cuisine\"],\n",
    "                               template=\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:59:46.059511Z",
     "iopub.status.busy": "2025-03-14T09:59:46.059232Z",
     "iopub.status.idle": "2025-03-14T09:59:46.063590Z",
     "shell.execute_reply": "2025-03-14T09:59:46.062637Z",
     "shell.execute_reply.started": "2025-03-14T09:59:46.059489Z"
    }
   },
   "outputs": [],
   "source": [
    "input_prompt=prompt_template1.format(cuisine=\"indian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T09:59:58.665411Z",
     "iopub.status.busy": "2025-03-14T09:59:58.665108Z",
     "iopub.status.idle": "2025-03-14T09:59:58.669756Z",
     "shell.execute_reply": "2025-03-14T09:59:58.669037Z",
     "shell.execute_reply.started": "2025-03-14T09:59:58.665385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to open a restaurant for indian food. Suggest a fency name for this\n"
     ]
    }
   ],
   "source": [
    "print(input_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T10:00:31.436124Z",
     "iopub.status.busy": "2025-03-14T10:00:31.435803Z",
     "iopub.status.idle": "2025-03-14T10:00:31.439834Z",
     "shell.execute_reply": "2025-03-14T10:00:31.438879Z",
     "shell.execute_reply.started": "2025-03-14T10:00:31.436101Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template2=PromptTemplate(input_variables=[\"book_name\"],\n",
    "                               template=\"Provide me a concise summary of the book {book_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T10:00:40.856716Z",
     "iopub.status.busy": "2025-03-14T10:00:40.856428Z",
     "iopub.status.idle": "2025-03-14T10:00:40.860396Z",
     "shell.execute_reply": "2025-03-14T10:00:40.859500Z",
     "shell.execute_reply.started": "2025-03-14T10:00:40.856692Z"
    }
   },
   "outputs": [],
   "source": [
    "input_prompt=prompt_template2.format(book_name=\"Alchemist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T10:00:50.531886Z",
     "iopub.status.busy": "2025-03-14T10:00:50.531540Z",
     "iopub.status.idle": "2025-03-14T10:00:50.536436Z",
     "shell.execute_reply": "2025-03-14T10:00:50.535618Z",
     "shell.execute_reply.started": "2025-03-14T10:00:50.531856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide me a concise summary of the book Alchemist\n"
     ]
    }
   ],
   "source": [
    "print(input_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T10:01:03.627297Z",
     "iopub.status.busy": "2025-03-14T10:01:03.627012Z",
     "iopub.status.idle": "2025-03-14T10:01:30.323527Z",
     "shell.execute_reply": "2025-03-14T10:01:30.322826Z",
     "shell.execute_reply.started": "2025-03-14T10:01:03.627276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProvide me a concise summary of the book Harry Potter\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Provide me a concise summary of the book Harry Potter and the Philosopher's Stone by J.K. Rowling.\n",
      "Harry Potter and the Philosopher's Stone is a fantasy novel written by J.K. Rowling. The book follows the adventures of a young wizard named Harry Potter who discovers that he is famous in the wizarding world. Harry learns that he is the son of two powerful wizards who were killed by the dark wizard, Lord Voldemort. After his parents' death, Voldemort attempted to kill Harry, but he failed and Harry survived with a lightning-shaped scar on his forehead.\n",
      "\n",
      "Harry is invited to attend Hogwarts School of Witchcraft and Wizardry, where he makes friends with Ron Weasley and Hermione Granger. Together, they become entangled in a mystery surrounding the powerful Sorcerer's Stone, which is hidden somewhere within the school. The trio must uncover the truth about the stone and prevent Voldemort from obtaining it, as he believes it will give him immortality.\n",
      "\n",
      "The book is full of magical creatures, spells, and potions, and introduces readers to the wizarding world and its rules and customs. Throughout the story, Harry learns about his parents' past and the reasons behind Voldemort's obsession with immortality. The book is a thrilling adventure that keeps readers on the edge of their seats as they follow Harry, Ron, and Hermione on their quest to stop Voldemort and save the wizarding world.\n",
      "\n",
      "Overall, Harry Potter and the Philosopher's Stone is a captivating and magical story that has become a classic in children's literature. It sets the stage for the rest of the Harry Potter series, introducing readers to the beloved characters and the richly detailed world of magic that they inhabit.\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template2, verbose=True)\n",
    "response= chain.run(\"Harry Potter\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
